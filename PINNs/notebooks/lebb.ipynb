{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAXPI PINN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell is you are using Google Colab\n",
    "!git clone https://github.com/CPSHub/LecturePhysicsAwareML.git\n",
    "%cd LecturePhysicsAwareML/PINNs\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, if you are working locally\n",
    "%cd ..\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from pinns.lebb import Config\n",
    "import pinns.lebb.cases as cases\n",
    "\n",
    "def get_data(config: Config):\n",
    "    EI = config.EI\n",
    "    L = config.L\n",
    "    F = config.F\n",
    "    q = config.q\n",
    "\n",
    "    if config.bc_case == 0:\n",
    "        sol_fun = partial(cases.bc_case_0, EI, F, L)\n",
    "        w_bc_coords = jnp.array([0.])\n",
    "        w_bc_values = jnp.array([0.])\n",
    "        w_x_bc_coords = jnp.array([0.])\n",
    "        w_x_bc_values = jnp.array([0.])\n",
    "        w_xx_bc_coords = jnp.array([L])\n",
    "        w_xx_bc_values = jnp.array([0.])\n",
    "        w_xxx_bc_coords = jnp.array([L])\n",
    "        w_xxx_bc_values = jnp.array([- F / EI])\n",
    "    elif config.bc_case == 1:\n",
    "        sol_fun = partial(cases.bc_case_1, EI, q, L)\n",
    "        w_bc_coords = jnp.array([0., L])\n",
    "        w_bc_values = jnp.array([0., 0.])\n",
    "        w_x_bc_coords = None\n",
    "        w_x_bc_values = None\n",
    "        w_xx_bc_coords = jnp.array([0., L])\n",
    "        w_xx_bc_values = jnp.array([0., 0.])\n",
    "        w_xxx_bc_coords = None\n",
    "        w_xxx_bc_values = None\n",
    "    else:\n",
    "        NotImplementedError(\"Data generation is not implemented for these boundary conditions.\")\n",
    "    \n",
    "\n",
    "    x = jnp.linspace(0.0, config.L, config.dataset_size).reshape(-1, 1)\n",
    "    y = jax.vmap(sol_fun)(x)\n",
    "    w, w_x, w_xx, w_xxx, w_xxxx = y\n",
    "\n",
    "    if config.non_dim:\n",
    "        x0 = L\n",
    "        q0 = 1.0 if q == 0.0 else q\n",
    "        w0 = q0 * x0**4 / EI\n",
    "\n",
    "        x = x / x0\n",
    "        w = w / w0\n",
    "        w_x = w_x / w0 * x0\n",
    "        w_xx = w_xx / w0 * x0**2\n",
    "        w_xxx = w_xxx / w0 * x0**3\n",
    "        w_xxxx = w_xxxx / w0 * x0**4\n",
    "\n",
    "        w_bc_coords = w_bc_coords / x0 if w_bc_coords is not None else None\n",
    "        w_x_bc_coords = w_x_bc_coords / x0 if w_x_bc_coords is not None else None\n",
    "        w_xx_bc_coords = w_xx_bc_coords / x0 if w_xx_bc_coords is not None else None\n",
    "        w_xxx_bc_coords = w_xx_bc_coords / x0 if w_xxx_bc_coords is not None else None\n",
    "        \n",
    "        w_bc_values = w_bc_values / w0 if w_bc_coords is not None else None\n",
    "        w_x_bc_values = w_x_bc_values / w0 * x0 if w_x_bc_coords is not None else None\n",
    "        w_xx_bc_values = w_xx_bc_values / w0 * x0**2 if w_xx_bc_coords is not None else None\n",
    "        w_xxx_bc_values = w_xxx_bc_values / w0 * x0**3 if w_xxx_bc_coords is not None else None\n",
    "        \n",
    "        q_out = q if q == 0.0 else 1.0\n",
    "        L_out = 1.0\n",
    "\n",
    "    else:\n",
    "        q_out = q / EI\n",
    "        L_out = L \n",
    "\n",
    "    bc = {\n",
    "        \"w_bc_coords\": w_bc_coords,\n",
    "        \"w_bc_values\": w_bc_values,\n",
    "        \"w_x_bc_coords\": w_x_bc_coords,\n",
    "        \"w_x_bc_values\": w_x_bc_values,\n",
    "        \"w_xx_bc_coords\": w_xx_bc_coords,\n",
    "        \"w_xx_bc_values\": w_xx_bc_values,\n",
    "        \"w_xxx_bc_coords\": w_xxx_bc_coords,\n",
    "        \"w_xxx_bc_values\": w_xxx_bc_values\n",
    "    }\n",
    "    return x, (w, w_x, w_xx, w_xxx, w_xxxx), bc, L_out, q_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PINN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Self\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jaxtyping import Array, PRNGKeyArray\n",
    "import paramax\n",
    "import equinox as eqx\n",
    "\n",
    "from pinns.nn import FFNN\n",
    "\n",
    "\n",
    "class PINN(eqx.Module):\n",
    "    nn: FFNN\n",
    "    q: float\n",
    "    L: float\n",
    "    w_bc_coords: paramax.NonTrainable | None\n",
    "    w_bc_values: paramax.NonTrainable | None\n",
    "    w_x_bc_coords: paramax.NonTrainable | None\n",
    "    w_x_bc_values: paramax.NonTrainable | None\n",
    "    w_xx_bc_coords: paramax.NonTrainable | None\n",
    "    w_xx_bc_values: paramax.NonTrainable | None\n",
    "    w_xxx_bc_coords: paramax.NonTrainable | None\n",
    "    w_xxx_bc_values: paramax.NonTrainable | None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        L: float,\n",
    "        q: float,\n",
    "        bc: dict[str, Array | None],\n",
    "        *,\n",
    "        key: PRNGKeyArray\n",
    "    ):\n",
    "        self.nn = FFNN(\n",
    "            in_features=1,\n",
    "            hidden_features=[8, 8],\n",
    "            out_features=1,\n",
    "            activations=[jax.nn.tanh, jax.nn.tanh],\n",
    "            final_activation=lambda x: x,\n",
    "            key=key\n",
    "        )\n",
    "        self.q = q\n",
    "        self.L = L\n",
    "\n",
    "        if bc[\"w_bc_coords\"] is None:\n",
    "            self.w_bc_coords = None\n",
    "            self.w_bc_values = None\n",
    "        else:\n",
    "            self.w_bc_coords = paramax.NonTrainable(bc[\"w_bc_coords\"].reshape(-1, 1))\n",
    "            self.w_bc_values = paramax.NonTrainable(bc[\"w_bc_values\"].reshape(-1, 1))\n",
    "\n",
    "        if bc[\"w_x_bc_coords\"] is None:\n",
    "            self.w_x_bc_coords = None\n",
    "            self.w_x_bc_values = None\n",
    "        else:\n",
    "            self.w_x_bc_coords = paramax.NonTrainable(bc[\"w_x_bc_coords\"].reshape(-1, 1))\n",
    "            self.w_x_bc_values = paramax.NonTrainable(bc[\"w_x_bc_values\"].reshape(-1, 1))\n",
    "\n",
    "        if bc[\"w_xx_bc_coords\"] is None:\n",
    "            self.w_xx_bc_coords = None\n",
    "            self.w_xx_bc_values = None\n",
    "        else:\n",
    "            self.w_xx_bc_coords = paramax.NonTrainable(bc[\"w_xx_bc_coords\"].reshape(-1, 1))\n",
    "            self.w_xx_bc_values = paramax.NonTrainable(bc[\"w_xx_bc_values\"].reshape(-1, 1))\n",
    "\n",
    "        if bc[\"w_xxx_bc_coords\"] is None:\n",
    "            self.w_xxx_bc_coords = None\n",
    "            self.w_xxx_bc_values = None\n",
    "        else:\n",
    "            self.w_xxx_bc_coords = paramax.NonTrainable(bc[\"w_xxx_bc_coords\"].reshape(-1, 1))\n",
    "            self.w_xxx_bc_values = paramax.NonTrainable(bc[\"w_xxx_bc_values\"].reshape(-1, 1))\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        w = self.w(self, x)\n",
    "        w_x = self.w_x(self, x)\n",
    "        w_xx = self.w_xx(self, x)\n",
    "        w_xxx = self.w_xxx(self, x)\n",
    "        w_xxxx = self.w_xxxx(self, x)\n",
    "\n",
    "        return w, w_x, w_xx, w_xxx, w_xxxx\n",
    "\n",
    "    def forward(self, x: Array) -> Tuple[Array, ...]:\n",
    "        x = x / self.L\n",
    "        return self.nn(x)\n",
    "\n",
    "    def w(self, model: Self, x: Array) -> Array:\n",
    "        return model.forward(x)\n",
    "\n",
    "    def w_x(self, model: Self,  x: Array) -> Array:\n",
    "        return jax.jacfwd(self.w, argnums=1)(model, x)[0]\n",
    "\n",
    "    def w_xx(self, model: Self, x: Array) -> Array:\n",
    "        return jax.jacfwd(self.w_x, argnums=1)(model, x)[0]\n",
    "\n",
    "    # def M(self, model: Self, x: Array) -> Array:\n",
    "    #     return - self.EI * self.w_xx(model, x)\n",
    "\n",
    "    def w_xxx(self, model: Self, x: Array) -> Array:\n",
    "        return jax.jacfwd(self.w_xx, argnums=1)(model, x)[0]\n",
    "\n",
    "    # def Q(self, model: Self, x: Array) -> Array:\n",
    "    #     return - self.EI * self.w_xxx(model, x)\n",
    "\n",
    "    def w_xxxx(self, model: Self, x: Array) -> Array:\n",
    "        return jax.jacfwd(self.w_xxx, argnums=1)(model, x)[0]\n",
    "\n",
    "    def res_w(self, model: Self, x: Array):\n",
    "        w_xxxx = self.w_xxxx(model, x)\n",
    "        rw = w_xxxx - self.q\n",
    "\n",
    "        return rw\n",
    "\n",
    "    def losses(self, model, x):\n",
    "        w_pred_fun = jax.vmap(self.w, (None, 0))\n",
    "        w_x_pred_fun = jax.vmap(self.w_x, (None, 0))\n",
    "        w_xx_pred_fun = jax.vmap(self.w_xx, (None, 0))\n",
    "        w_xxx_pred_fun = jax.vmap(self.w_xxx, (None, 0))\n",
    "\n",
    "        res_w_fun = jax.vmap(self.res_w, (None, 0))\n",
    "        \n",
    "        if self.w_bc_coords is None:\n",
    "            w_bc_loss = jnp.array(0.)\n",
    "        else:\n",
    "            w_bc_pred = w_pred_fun(model, self.w_bc_coords)\n",
    "            w_bc_loss = jnp.mean((w_bc_pred - self.w_bc_values)**2)\n",
    "\n",
    "        if self.w_x_bc_coords is None:\n",
    "            w_x_bc_loss = jnp.array(0.)\n",
    "        else:\n",
    "            w_x_bc_pred = w_x_pred_fun(model, self.w_x_bc_coords)\n",
    "            w_x_bc_loss = jnp.mean((w_x_bc_pred - self.w_x_bc_values)**2)\n",
    "\n",
    "        if self.w_xx_bc_coords is None:\n",
    "            w_xx_bc_loss = jnp.array(0.)\n",
    "        else:\n",
    "            w_xx_bc_pred = w_xx_pred_fun(model, self.w_xx_bc_coords)\n",
    "            w_xx_bc_loss = jnp.mean((w_xx_bc_pred - self.w_xx_bc_values)**2)\n",
    "\n",
    "        if self.w_xxx_bc_coords is None:\n",
    "            w_xxx_bc_loss = jnp.array(0.)\n",
    "        else:\n",
    "            w_xxx_bc_pred = w_xxx_pred_fun(model, self.w_xxx_bc_coords)\n",
    "            w_xxx_bc_loss = jnp.mean((w_xxx_bc_pred - self.w_xxx_bc_values)**2)\n",
    "\n",
    "        rw_pred = res_w_fun(model, x)\n",
    "        rw_loss = jnp.mean(rw_pred**2)\n",
    "\n",
    "        loss_dict = {\n",
    "            \"w_bc\": w_bc_loss,\n",
    "            \"w_x_bc\": w_x_bc_loss,\n",
    "            \"w_xx_bc\": w_xx_bc_loss,\n",
    "            \"w_xxx_bc\": w_xxx_bc_loss,\n",
    "            \"rw\": rw_loss\n",
    "        }\n",
    "        return loss_dict\n",
    "\n",
    "    def loss(self, model, weights, x):\n",
    "        losses = self.losses(model, x)\n",
    "        weighted_losses = jax.tree.map(lambda x, y: x * y, losses, weights)\n",
    "        loss = jax.tree.reduce(lambda x, y: x + y, weighted_losses)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(bc_case: int, non_dim: bool):\n",
    "    if bc_case == 0:\n",
    "        EI = 1e6\n",
    "        L = 1.0\n",
    "        F = 1.0\n",
    "        q = 0.0\n",
    "    elif bc_case == 1:\n",
    "        EI = 1e6\n",
    "        L = 1.0\n",
    "        F = None\n",
    "        q = 1.0\n",
    "    else:\n",
    "        NotImplementedError(\"No configuration implemented for these boundary conditions.\")\n",
    "\n",
    "    config = Config(\n",
    "        EI=EI,\n",
    "        L=L,\n",
    "        F=F,\n",
    "        q=q,\n",
    "        bc_case=bc_case,\n",
    "        dataset_size=1_000,\n",
    "        steps=50_000,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=32,\n",
    "        weights={\n",
    "            \"w_bc\": 1.0,\n",
    "            \"w_x_bc\": 1.0,\n",
    "            \"w_xx_bc\": 1.0,\n",
    "            \"w_xxx_bc\": 1.0,\n",
    "            \"rw\": 1.0\n",
    "        },\n",
    "        non_dim=non_dim\n",
    "    )\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinns.lebb import train\n",
    "\n",
    "\n",
    "config = get_config(bc_case=0, non_dim=False)\n",
    "x, y, bc, L, q = get_data(config)\n",
    "\n",
    "key = jax.random.PRNGKey(1234)\n",
    "model = PINN(L, q, bc, key=key)\n",
    "\n",
    "model = train(model, x, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinns.lebb import evaluate\n",
    "\n",
    "evaluate(model, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "#### 1. Dimensionality:\n",
    "\n",
    "For `bc_case=0`, ...\n",
    "\n",
    "a) Set the parameter EI to $10^6$ and set `non_dim=False`. Can the model approximate the solution.\n",
    "\n",
    "b) Try setting the parameter EI to $1.0$. Can the model approximate the solution now?\n",
    "\n",
    "c) Set EI back to $10^6$ and set `non_dim=True`. Can the model fit the data now?\n",
    "\n",
    "d) Summarize your findings.\n",
    "\n",
    "#### 2. Boundary conditions\n",
    "\n",
    "Fix the boundary conditions for `bc_case=1` withing `get_data()`. Now calibrate the PINN and test your implementation againt the analytical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
